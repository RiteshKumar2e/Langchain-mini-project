# ─────────────────────────────────────────────────────────────────────────────
# LangChain RAG Platform — Environment Variables
# Copy this file to .env and replace all placeholder values.
# ─────────────────────────────────────────────────────────────────────────────

# ── Groq LLM ─────────────────────────────────────────────────────────────────
# Get your free key at: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Model options: llama-3.3-70b-versatile | mixtral-8x7b-32768 | gemma2-9b-it
GROQ_MODEL=llama-3.3-70b-versatile

# Sampling temperature: 0.0 = deterministic, 1.0 = creative
LLM_TEMPERATURE=0.2

# ── Embeddings (local HuggingFace — no API key required) ─────────────────────
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ── Document paths ────────────────────────────────────────────────────────────
DOCUMENTS_PATH=./documents
VECTOR_STORE_PATH=./vector_store

# ── Chunking (empirically tuned for technical documentation) ──────────────────
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# ── Retrieval ─────────────────────────────────────────────────────────────────
RETRIEVAL_K=5
# Minimum similarity score [0.0–1.0] — set to 0 to include all retrieved chunks
RETRIEVAL_SCORE_THRESHOLD=0.0

# ── Features ──────────────────────────────────────────────────────────────────
ENABLE_CONVERSATION_MEMORY=true

# ── CORS ──────────────────────────────────────────────────────────────────────
CORS_ORIGINS=http://localhost:5173,http://localhost:3000
