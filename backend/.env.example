# ─────────────────────────────────────────────
# LangChain RAG Backend — Environment Variables
# ─────────────────────────────────────────────

# ── LLM Provider (choose ONE) ────────────────
# Option A: OpenAI  (https://platform.openai.com/api-keys)
OPENAI_API_KEY=your_openai_api_key_here

# Option B: Groq   (https://console.groq.com/keys)
GROQ_API_KEY=your_groq_api_key_here

# ── Provider selector ─────────────────────────
# Set to "openai" or "groq"
LLM_PROVIDER=groq

# ── Model names ──────────────────────────────
OPENAI_MODEL=gpt-4o-mini
GROQ_MODEL=llama-3.3-70b-versatile

# ── Embedding settings ───────────────────────
# "openai"    → OpenAI text-embedding-3-small (requires OPENAI_API_KEY)
# "huggingface" → all-MiniLM-L6-v2 (free, local, no key needed)
EMBEDDING_PROVIDER=huggingface

# ── Vector store path ────────────────────────
VECTOR_STORE_PATH=./vector_store

# ── Document settings ────────────────────────
DOCUMENTS_PATH=./documents
CHUNK_SIZE=800
CHUNK_OVERLAP=100

# ── Retrieval settings ───────────────────────
RETRIEVAL_K=5

# ── CORS origins (space/comma separated) ─────
CORS_ORIGINS=http://localhost:5173,http://localhost:3000
